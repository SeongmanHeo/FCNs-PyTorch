{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNs using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the lib.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for reading and displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# PyTorch lib. and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcn reading ucr\n",
    "def readucr(filename):    \n",
    "    data = np.loadtxt(filename)\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  4\n",
      "batch size:  10.0\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "fname = 'Trace'\n",
    "x_train, y_train = readucr(fname+'_TRAIN.txt')\n",
    "x_test, y_test = readucr(fname+'_TEST.txt')\n",
    "nb_classes = len(np.unique(y_test))\n",
    "batch_size = min(x_train.shape[0]/10, 16)\n",
    "print('classes: ', nb_classes)\n",
    "print('batch size: ', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# converting type of data\n",
    "print(x_train.dtype)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization: Min-Max Scaler, range: (0 ~ 1)*nb_classes\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "# converting type of data\n",
    "print(y_train.dtype)\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encoding\n",
    "Y_train = np.eye(nb_classes)[y_train]\n",
    "Y_test = np.eye(nb_classes)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.dtype)\n",
    "Y_train = Y_train.astype('int64')\n",
    "Y_test = Y_test.astype('int64')\n",
    "print(Y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 275)\n",
      "(100, 275)\n",
      "(100, 4)\n",
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization: Standard Scaler or z-score normalization (평균 0, 표준 편차 1인 표준분포 꼴 데이터로 만듬)\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean)/(x_train_std)\n",
    "x_test = (x_test - x_train_mean)/(x_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing: for simple computations test\n",
    "# nb_slice = 100\n",
    "# x_train = x_train[:nb_slice][:]\n",
    "# x_test = x_test[:nb_slice-90][:]\n",
    "# Y_train = Y_train[:nb_slice][:]\n",
    "# Y_test = Y_test[:nb_slice-90][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:  (100, 1, 1, 275)\n",
      "x_test:  (100, 1, 1, 275)\n",
      "dtpyes:\n",
      "float32\n",
      "float32\n",
      "int64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 1, 275)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 1, 275)\n",
    "print('x_train: ', x_train.shape)\n",
    "print('x_test: ', x_test.shape)\n",
    "print('dtpyes:')\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "print(Y_train.dtype)\n",
    "print(Y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  torch.Size([100, 1, 1, 275]) Y_train shape:  torch.Size([100, 4])\n",
      "x_test shape:  torch.Size([100, 1, 1, 275]) Y_test shape:  torch.Size([100, 4])\n",
      "dtpyes:\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.int64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# converting numpy.array to tensor\n",
    "x_train = torch.from_numpy(x_train)\n",
    "Y_train = torch.from_numpy(Y_train)\n",
    "x_test = torch.from_numpy(x_test)\n",
    "Y_test = torch.from_numpy(Y_test)\n",
    "print('x_train shape: ', x_train.shape, 'Y_train shape: ', Y_train.shape)\n",
    "print('x_test shape: ', x_test.shape, 'Y_test shape: ', Y_test.shape)\n",
    "print('dtpyes:')\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "print(Y_train.dtype)\n",
    "print(Y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing CNNs using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNs(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(FCNs, self).__init__()        \n",
    "        self.layer1 = nn.Sequential(                        \n",
    "            nn.Conv2d(1, 128, kernel_size=(1, 8), stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())            \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(1, 5), stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=(1, 3), stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8704, 128),            \n",
    "            nn.Linear(128, nb_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print('input', x.size())\n",
    "        out = self.layer1(x)\n",
    "        # print('layer1', out.size())\n",
    "        out = self.layer2(out)\n",
    "        # print('layer2', out.size())\n",
    "        out = self.layer3(out)\n",
    "        # print('layer3', out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        # print('reshape', out.size())\n",
    "        out = self.fc(out)\n",
    "        # print('fc', out.size())        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNs(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 128, kernel_size=(1, 8), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 5), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(1, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout2d(p=0.2)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=8704, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = FCNs()\n",
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# defining the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining the number of epochs\n",
    "n_epochs = 500\n",
    "# empty list to store training losses\n",
    "train_losses = []\n",
    "# empty list to store validation losses\n",
    "val_losses = []\n",
    "\n",
    "# defining train pro.\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting variables\n",
    "    Xtrain = Variable(x_train)\n",
    "    Ytrain = Variable(Y_train)\n",
    "    Xtest = Variable(x_test)\n",
    "    Ytest = Variable(Y_test)\n",
    "    # getting the training and testing set\n",
    "    if torch.cuda.is_available():\n",
    "        # print('GPU available: ', torch.cuda.is_available())\n",
    "        Xtrain = x_train.cuda()\n",
    "        Ytrain = Y_train.cuda()\n",
    "        Xtest = x_test.cuda()\n",
    "        Ytest = Y_test.cuda()\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    # prediction for training and validation set\n",
    "    output_train = model(Xtrain)\n",
    "    output_test = model(Xtest)\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, torch.max(Ytrain, 1)[1])\n",
    "    loss_test = criterion(output_test, torch.max(Ytest, 1)[1])\n",
    "    # tensor -> value\n",
    "    train_losses.append(loss_train.item())\n",
    "    val_losses.append(loss_test.item())\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    # printing the validation loss\n",
    "    if epoch%1 == 0:        \n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_test)\n",
    "    # clear memory\n",
    "    del Xtrain, Ytrain, Xtest, Ytest\n",
    "    del loss_train, loss_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 \t loss : tensor(1.3804, device='cuda:0')\n",
      "Epoch :  2 \t loss : tensor(39.3595, device='cuda:0')\n",
      "Epoch :  3 \t loss : tensor(27.6734, device='cuda:0')\n",
      "Epoch :  4 \t loss : tensor(30.2659, device='cuda:0')\n",
      "Epoch :  5 \t loss : tensor(31.1450, device='cuda:0')\n",
      "Epoch :  6 \t loss : tensor(15.6703, device='cuda:0')\n",
      "Epoch :  7 \t loss : tensor(13.1924, device='cuda:0')\n",
      "Epoch :  8 \t loss : tensor(13.8626, device='cuda:0')\n",
      "Epoch :  9 \t loss : tensor(5.4149, device='cuda:0')\n",
      "Epoch :  10 \t loss : tensor(8.6498, device='cuda:0')\n",
      "Epoch :  11 \t loss : tensor(6.0487, device='cuda:0')\n",
      "Epoch :  12 \t loss : tensor(5.1851, device='cuda:0')\n",
      "Epoch :  13 \t loss : tensor(5.1658, device='cuda:0')\n",
      "Epoch :  14 \t loss : tensor(4.9805, device='cuda:0')\n",
      "Epoch :  15 \t loss : tensor(4.5365, device='cuda:0')\n",
      "Epoch :  16 \t loss : tensor(3.6556, device='cuda:0')\n",
      "Epoch :  17 \t loss : tensor(3.3306, device='cuda:0')\n",
      "Epoch :  18 \t loss : tensor(3.4765, device='cuda:0')\n",
      "Epoch :  19 \t loss : tensor(2.8196, device='cuda:0')\n",
      "Epoch :  20 \t loss : tensor(3.1442, device='cuda:0')\n",
      "Epoch :  21 \t loss : tensor(3.5062, device='cuda:0')\n",
      "Epoch :  22 \t loss : tensor(3.2373, device='cuda:0')\n",
      "Epoch :  23 \t loss : tensor(2.5878, device='cuda:0')\n",
      "Epoch :  24 \t loss : tensor(2.2592, device='cuda:0')\n",
      "Epoch :  25 \t loss : tensor(2.0752, device='cuda:0')\n",
      "Epoch :  26 \t loss : tensor(2.0422, device='cuda:0')\n",
      "Epoch :  27 \t loss : tensor(2.3244, device='cuda:0')\n",
      "Epoch :  28 \t loss : tensor(2.0178, device='cuda:0')\n",
      "Epoch :  29 \t loss : tensor(1.9082, device='cuda:0')\n",
      "Epoch :  30 \t loss : tensor(1.8016, device='cuda:0')\n",
      "Epoch :  31 \t loss : tensor(2.1660, device='cuda:0')\n",
      "Epoch :  32 \t loss : tensor(1.8830, device='cuda:0')\n",
      "Epoch :  33 \t loss : tensor(1.7407, device='cuda:0')\n",
      "Epoch :  34 \t loss : tensor(1.6988, device='cuda:0')\n",
      "Epoch :  35 \t loss : tensor(1.7258, device='cuda:0')\n",
      "Epoch :  36 \t loss : tensor(1.6091, device='cuda:0')\n",
      "Epoch :  37 \t loss : tensor(1.4291, device='cuda:0')\n",
      "Epoch :  38 \t loss : tensor(1.5363, device='cuda:0')\n",
      "Epoch :  39 \t loss : tensor(1.4808, device='cuda:0')\n",
      "Epoch :  40 \t loss : tensor(1.6056, device='cuda:0')\n",
      "Epoch :  41 \t loss : tensor(1.5114, device='cuda:0')\n",
      "Epoch :  42 \t loss : tensor(1.5804, device='cuda:0')\n",
      "Epoch :  43 \t loss : tensor(1.5012, device='cuda:0')\n",
      "Epoch :  44 \t loss : tensor(1.4551, device='cuda:0')\n",
      "Epoch :  45 \t loss : tensor(1.6309, device='cuda:0')\n",
      "Epoch :  46 \t loss : tensor(1.6620, device='cuda:0')\n",
      "Epoch :  47 \t loss : tensor(1.5127, device='cuda:0')\n",
      "Epoch :  48 \t loss : tensor(1.5282, device='cuda:0')\n",
      "Epoch :  49 \t loss : tensor(1.4763, device='cuda:0')\n",
      "Epoch :  50 \t loss : tensor(1.5757, device='cuda:0')\n",
      "Epoch :  51 \t loss : tensor(1.5659, device='cuda:0')\n",
      "Epoch :  52 \t loss : tensor(1.4645, device='cuda:0')\n",
      "Epoch :  53 \t loss : tensor(1.4599, device='cuda:0')\n",
      "Epoch :  54 \t loss : tensor(1.4308, device='cuda:0')\n",
      "Epoch :  55 \t loss : tensor(1.4044, device='cuda:0')\n",
      "Epoch :  56 \t loss : tensor(1.4981, device='cuda:0')\n",
      "Epoch :  57 \t loss : tensor(1.4978, device='cuda:0')\n",
      "Epoch :  58 \t loss : tensor(1.4755, device='cuda:0')\n",
      "Epoch :  59 \t loss : tensor(1.4696, device='cuda:0')\n",
      "Epoch :  60 \t loss : tensor(1.4362, device='cuda:0')\n",
      "Epoch :  61 \t loss : tensor(1.4186, device='cuda:0')\n",
      "Epoch :  62 \t loss : tensor(1.4185, device='cuda:0')\n",
      "Epoch :  63 \t loss : tensor(1.4815, device='cuda:0')\n",
      "Epoch :  64 \t loss : tensor(1.5052, device='cuda:0')\n",
      "Epoch :  65 \t loss : tensor(1.4558, device='cuda:0')\n",
      "Epoch :  66 \t loss : tensor(1.4390, device='cuda:0')\n",
      "Epoch :  67 \t loss : tensor(1.4297, device='cuda:0')\n",
      "Epoch :  68 \t loss : tensor(1.4442, device='cuda:0')\n",
      "Epoch :  69 \t loss : tensor(1.4773, device='cuda:0')\n",
      "Epoch :  70 \t loss : tensor(1.4610, device='cuda:0')\n",
      "Epoch :  71 \t loss : tensor(1.4705, device='cuda:0')\n",
      "Epoch :  72 \t loss : tensor(1.4644, device='cuda:0')\n",
      "Epoch :  73 \t loss : tensor(1.4445, device='cuda:0')\n",
      "Epoch :  74 \t loss : tensor(1.3954, device='cuda:0')\n",
      "Epoch :  75 \t loss : tensor(1.4149, device='cuda:0')\n",
      "Epoch :  76 \t loss : tensor(1.4006, device='cuda:0')\n",
      "Epoch :  77 \t loss : tensor(1.4302, device='cuda:0')\n",
      "Epoch :  78 \t loss : tensor(1.4425, device='cuda:0')\n",
      "Epoch :  79 \t loss : tensor(1.4546, device='cuda:0')\n",
      "Epoch :  80 \t loss : tensor(1.4431, device='cuda:0')\n",
      "Epoch :  81 \t loss : tensor(1.4223, device='cuda:0')\n",
      "Epoch :  82 \t loss : tensor(1.4405, device='cuda:0')\n",
      "Epoch :  83 \t loss : tensor(1.4326, device='cuda:0')\n",
      "Epoch :  84 \t loss : tensor(1.4540, device='cuda:0')\n",
      "Epoch :  85 \t loss : tensor(1.4538, device='cuda:0')\n",
      "Epoch :  86 \t loss : tensor(1.4289, device='cuda:0')\n",
      "Epoch :  87 \t loss : tensor(1.4706, device='cuda:0')\n",
      "Epoch :  88 \t loss : tensor(1.4450, device='cuda:0')\n",
      "Epoch :  89 \t loss : tensor(1.4487, device='cuda:0')\n",
      "Epoch :  90 \t loss : tensor(1.4608, device='cuda:0')\n",
      "Epoch :  91 \t loss : tensor(1.4077, device='cuda:0')\n",
      "Epoch :  92 \t loss : tensor(1.4368, device='cuda:0')\n",
      "Epoch :  93 \t loss : tensor(1.4570, device='cuda:0')\n",
      "Epoch :  94 \t loss : tensor(1.4632, device='cuda:0')\n",
      "Epoch :  95 \t loss : tensor(1.4479, device='cuda:0')\n",
      "Epoch :  96 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  97 \t loss : tensor(1.4292, device='cuda:0')\n",
      "Epoch :  98 \t loss : tensor(1.4160, device='cuda:0')\n",
      "Epoch :  99 \t loss : tensor(1.4191, device='cuda:0')\n",
      "Epoch :  100 \t loss : tensor(1.4239, device='cuda:0')\n",
      "Epoch :  101 \t loss : tensor(1.4568, device='cuda:0')\n",
      "Epoch :  102 \t loss : tensor(1.4828, device='cuda:0')\n",
      "Epoch :  103 \t loss : tensor(1.4729, device='cuda:0')\n",
      "Epoch :  104 \t loss : tensor(1.4287, device='cuda:0')\n",
      "Epoch :  105 \t loss : tensor(1.4028, device='cuda:0')\n",
      "Epoch :  106 \t loss : tensor(1.4407, device='cuda:0')\n",
      "Epoch :  107 \t loss : tensor(1.4514, device='cuda:0')\n",
      "Epoch :  108 \t loss : tensor(1.4478, device='cuda:0')\n",
      "Epoch :  109 \t loss : tensor(1.4535, device='cuda:0')\n",
      "Epoch :  110 \t loss : tensor(1.4433, device='cuda:0')\n",
      "Epoch :  111 \t loss : tensor(1.4544, device='cuda:0')\n",
      "Epoch :  112 \t loss : tensor(1.4201, device='cuda:0')\n",
      "Epoch :  113 \t loss : tensor(1.4579, device='cuda:0')\n",
      "Epoch :  114 \t loss : tensor(1.4122, device='cuda:0')\n",
      "Epoch :  115 \t loss : tensor(1.4134, device='cuda:0')\n",
      "Epoch :  116 \t loss : tensor(1.4329, device='cuda:0')\n",
      "Epoch :  117 \t loss : tensor(1.4717, device='cuda:0')\n",
      "Epoch :  118 \t loss : tensor(1.4388, device='cuda:0')\n",
      "Epoch :  119 \t loss : tensor(1.4756, device='cuda:0')\n",
      "Epoch :  120 \t loss : tensor(1.4137, device='cuda:0')\n",
      "Epoch :  121 \t loss : tensor(1.4248, device='cuda:0')\n",
      "Epoch :  122 \t loss : tensor(1.4263, device='cuda:0')\n",
      "Epoch :  123 \t loss : tensor(1.4302, device='cuda:0')\n",
      "Epoch :  124 \t loss : tensor(1.4283, device='cuda:0')\n",
      "Epoch :  125 \t loss : tensor(1.4092, device='cuda:0')\n",
      "Epoch :  126 \t loss : tensor(1.4410, device='cuda:0')\n",
      "Epoch :  127 \t loss : tensor(1.4358, device='cuda:0')\n",
      "Epoch :  128 \t loss : tensor(1.4368, device='cuda:0')\n",
      "Epoch :  129 \t loss : tensor(1.4623, device='cuda:0')\n",
      "Epoch :  130 \t loss : tensor(1.4184, device='cuda:0')\n",
      "Epoch :  131 \t loss : tensor(1.4057, device='cuda:0')\n",
      "Epoch :  132 \t loss : tensor(1.4179, device='cuda:0')\n",
      "Epoch :  133 \t loss : tensor(1.4311, device='cuda:0')\n",
      "Epoch :  134 \t loss : tensor(1.4169, device='cuda:0')\n",
      "Epoch :  135 \t loss : tensor(1.4408, device='cuda:0')\n",
      "Epoch :  136 \t loss : tensor(1.4564, device='cuda:0')\n",
      "Epoch :  137 \t loss : tensor(1.4175, device='cuda:0')\n",
      "Epoch :  138 \t loss : tensor(1.4298, device='cuda:0')\n",
      "Epoch :  139 \t loss : tensor(1.4220, device='cuda:0')\n",
      "Epoch :  140 \t loss : tensor(1.4365, device='cuda:0')\n",
      "Epoch :  141 \t loss : tensor(1.4335, device='cuda:0')\n",
      "Epoch :  142 \t loss : tensor(1.4438, device='cuda:0')\n",
      "Epoch :  143 \t loss : tensor(1.4282, device='cuda:0')\n",
      "Epoch :  144 \t loss : tensor(1.4028, device='cuda:0')\n",
      "Epoch :  145 \t loss : tensor(1.4349, device='cuda:0')\n",
      "Epoch :  146 \t loss : tensor(1.4379, device='cuda:0')\n",
      "Epoch :  147 \t loss : tensor(1.4445, device='cuda:0')\n",
      "Epoch :  148 \t loss : tensor(1.4629, device='cuda:0')\n",
      "Epoch :  149 \t loss : tensor(1.4175, device='cuda:0')\n",
      "Epoch :  150 \t loss : tensor(1.4369, device='cuda:0')\n",
      "Epoch :  151 \t loss : tensor(1.4276, device='cuda:0')\n",
      "Epoch :  152 \t loss : tensor(1.4497, device='cuda:0')\n",
      "Epoch :  153 \t loss : tensor(1.4166, device='cuda:0')\n",
      "Epoch :  154 \t loss : tensor(1.4236, device='cuda:0')\n",
      "Epoch :  155 \t loss : tensor(1.4278, device='cuda:0')\n",
      "Epoch :  156 \t loss : tensor(1.4171, device='cuda:0')\n",
      "Epoch :  157 \t loss : tensor(1.4049, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  158 \t loss : tensor(1.4223, device='cuda:0')\n",
      "Epoch :  159 \t loss : tensor(1.4316, device='cuda:0')\n",
      "Epoch :  160 \t loss : tensor(1.4565, device='cuda:0')\n",
      "Epoch :  161 \t loss : tensor(1.4459, device='cuda:0')\n",
      "Epoch :  162 \t loss : tensor(1.4484, device='cuda:0')\n",
      "Epoch :  163 \t loss : tensor(1.3938, device='cuda:0')\n",
      "Epoch :  164 \t loss : tensor(1.4498, device='cuda:0')\n",
      "Epoch :  165 \t loss : tensor(1.4800, device='cuda:0')\n",
      "Epoch :  166 \t loss : tensor(1.4467, device='cuda:0')\n",
      "Epoch :  167 \t loss : tensor(1.4454, device='cuda:0')\n",
      "Epoch :  168 \t loss : tensor(1.4317, device='cuda:0')\n",
      "Epoch :  169 \t loss : tensor(1.4339, device='cuda:0')\n",
      "Epoch :  170 \t loss : tensor(1.4391, device='cuda:0')\n",
      "Epoch :  171 \t loss : tensor(1.4807, device='cuda:0')\n",
      "Epoch :  172 \t loss : tensor(1.4543, device='cuda:0')\n",
      "Epoch :  173 \t loss : tensor(1.4395, device='cuda:0')\n",
      "Epoch :  174 \t loss : tensor(1.4542, device='cuda:0')\n",
      "Epoch :  175 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  176 \t loss : tensor(1.4242, device='cuda:0')\n",
      "Epoch :  177 \t loss : tensor(1.4344, device='cuda:0')\n",
      "Epoch :  178 \t loss : tensor(1.4091, device='cuda:0')\n",
      "Epoch :  179 \t loss : tensor(1.4162, device='cuda:0')\n",
      "Epoch :  180 \t loss : tensor(1.4631, device='cuda:0')\n",
      "Epoch :  181 \t loss : tensor(1.4009, device='cuda:0')\n",
      "Epoch :  182 \t loss : tensor(1.4334, device='cuda:0')\n",
      "Epoch :  183 \t loss : tensor(1.4178, device='cuda:0')\n",
      "Epoch :  184 \t loss : tensor(1.4349, device='cuda:0')\n",
      "Epoch :  185 \t loss : tensor(1.4141, device='cuda:0')\n",
      "Epoch :  186 \t loss : tensor(1.4418, device='cuda:0')\n",
      "Epoch :  187 \t loss : tensor(1.4157, device='cuda:0')\n",
      "Epoch :  188 \t loss : tensor(1.4424, device='cuda:0')\n",
      "Epoch :  189 \t loss : tensor(1.4244, device='cuda:0')\n",
      "Epoch :  190 \t loss : tensor(1.4296, device='cuda:0')\n",
      "Epoch :  191 \t loss : tensor(1.4261, device='cuda:0')\n",
      "Epoch :  192 \t loss : tensor(1.4349, device='cuda:0')\n",
      "Epoch :  193 \t loss : tensor(1.4361, device='cuda:0')\n",
      "Epoch :  194 \t loss : tensor(1.4375, device='cuda:0')\n",
      "Epoch :  195 \t loss : tensor(1.4526, device='cuda:0')\n",
      "Epoch :  196 \t loss : tensor(1.4285, device='cuda:0')\n",
      "Epoch :  197 \t loss : tensor(1.4365, device='cuda:0')\n",
      "Epoch :  198 \t loss : tensor(1.4566, device='cuda:0')\n",
      "Epoch :  199 \t loss : tensor(1.4208, device='cuda:0')\n",
      "Epoch :  200 \t loss : tensor(1.4002, device='cuda:0')\n",
      "Epoch :  201 \t loss : tensor(1.4213, device='cuda:0')\n",
      "Epoch :  202 \t loss : tensor(1.4458, device='cuda:0')\n",
      "Epoch :  203 \t loss : tensor(1.4146, device='cuda:0')\n",
      "Epoch :  204 \t loss : tensor(1.4060, device='cuda:0')\n",
      "Epoch :  205 \t loss : tensor(1.4184, device='cuda:0')\n",
      "Epoch :  206 \t loss : tensor(1.4329, device='cuda:0')\n",
      "Epoch :  207 \t loss : tensor(1.4408, device='cuda:0')\n",
      "Epoch :  208 \t loss : tensor(1.4188, device='cuda:0')\n",
      "Epoch :  209 \t loss : tensor(1.4393, device='cuda:0')\n",
      "Epoch :  210 \t loss : tensor(1.4497, device='cuda:0')\n",
      "Epoch :  211 \t loss : tensor(1.4357, device='cuda:0')\n",
      "Epoch :  212 \t loss : tensor(1.4308, device='cuda:0')\n",
      "Epoch :  213 \t loss : tensor(1.4348, device='cuda:0')\n",
      "Epoch :  214 \t loss : tensor(1.4225, device='cuda:0')\n",
      "Epoch :  215 \t loss : tensor(1.4152, device='cuda:0')\n",
      "Epoch :  216 \t loss : tensor(1.4462, device='cuda:0')\n",
      "Epoch :  217 \t loss : tensor(1.4135, device='cuda:0')\n",
      "Epoch :  218 \t loss : tensor(1.4211, device='cuda:0')\n",
      "Epoch :  219 \t loss : tensor(1.4356, device='cuda:0')\n",
      "Epoch :  220 \t loss : tensor(1.4222, device='cuda:0')\n",
      "Epoch :  221 \t loss : tensor(1.4397, device='cuda:0')\n",
      "Epoch :  222 \t loss : tensor(1.4166, device='cuda:0')\n",
      "Epoch :  223 \t loss : tensor(1.4309, device='cuda:0')\n",
      "Epoch :  224 \t loss : tensor(1.4655, device='cuda:0')\n",
      "Epoch :  225 \t loss : tensor(1.4399, device='cuda:0')\n",
      "Epoch :  226 \t loss : tensor(1.4519, device='cuda:0')\n",
      "Epoch :  227 \t loss : tensor(1.4423, device='cuda:0')\n",
      "Epoch :  228 \t loss : tensor(1.4183, device='cuda:0')\n",
      "Epoch :  229 \t loss : tensor(1.4077, device='cuda:0')\n",
      "Epoch :  230 \t loss : tensor(1.4090, device='cuda:0')\n",
      "Epoch :  231 \t loss : tensor(1.4237, device='cuda:0')\n",
      "Epoch :  232 \t loss : tensor(1.4260, device='cuda:0')\n",
      "Epoch :  233 \t loss : tensor(1.4088, device='cuda:0')\n",
      "Epoch :  234 \t loss : tensor(1.4404, device='cuda:0')\n",
      "Epoch :  235 \t loss : tensor(1.4544, device='cuda:0')\n",
      "Epoch :  236 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  237 \t loss : tensor(1.4314, device='cuda:0')\n",
      "Epoch :  238 \t loss : tensor(1.4516, device='cuda:0')\n",
      "Epoch :  239 \t loss : tensor(1.4440, device='cuda:0')\n",
      "Epoch :  240 \t loss : tensor(1.4631, device='cuda:0')\n",
      "Epoch :  241 \t loss : tensor(1.4265, device='cuda:0')\n",
      "Epoch :  242 \t loss : tensor(1.4134, device='cuda:0')\n",
      "Epoch :  243 \t loss : tensor(1.4286, device='cuda:0')\n",
      "Epoch :  244 \t loss : tensor(1.4341, device='cuda:0')\n",
      "Epoch :  245 \t loss : tensor(1.4409, device='cuda:0')\n",
      "Epoch :  246 \t loss : tensor(1.4305, device='cuda:0')\n",
      "Epoch :  247 \t loss : tensor(1.4189, device='cuda:0')\n",
      "Epoch :  248 \t loss : tensor(1.4333, device='cuda:0')\n",
      "Epoch :  249 \t loss : tensor(1.4489, device='cuda:0')\n",
      "Epoch :  250 \t loss : tensor(1.4602, device='cuda:0')\n",
      "Epoch :  251 \t loss : tensor(1.4332, device='cuda:0')\n",
      "Epoch :  252 \t loss : tensor(1.4328, device='cuda:0')\n",
      "Epoch :  253 \t loss : tensor(1.4284, device='cuda:0')\n",
      "Epoch :  254 \t loss : tensor(1.4162, device='cuda:0')\n",
      "Epoch :  255 \t loss : tensor(1.4357, device='cuda:0')\n",
      "Epoch :  256 \t loss : tensor(1.4162, device='cuda:0')\n",
      "Epoch :  257 \t loss : tensor(1.4514, device='cuda:0')\n",
      "Epoch :  258 \t loss : tensor(1.4019, device='cuda:0')\n",
      "Epoch :  259 \t loss : tensor(1.3936, device='cuda:0')\n",
      "Epoch :  260 \t loss : tensor(1.4222, device='cuda:0')\n",
      "Epoch :  261 \t loss : tensor(1.4220, device='cuda:0')\n",
      "Epoch :  262 \t loss : tensor(1.4516, device='cuda:0')\n",
      "Epoch :  263 \t loss : tensor(1.4202, device='cuda:0')\n",
      "Epoch :  264 \t loss : tensor(1.4317, device='cuda:0')\n",
      "Epoch :  265 \t loss : tensor(1.4397, device='cuda:0')\n",
      "Epoch :  266 \t loss : tensor(1.4193, device='cuda:0')\n",
      "Epoch :  267 \t loss : tensor(1.4109, device='cuda:0')\n",
      "Epoch :  268 \t loss : tensor(1.4099, device='cuda:0')\n",
      "Epoch :  269 \t loss : tensor(1.4427, device='cuda:0')\n",
      "Epoch :  270 \t loss : tensor(1.4180, device='cuda:0')\n",
      "Epoch :  271 \t loss : tensor(1.4196, device='cuda:0')\n",
      "Epoch :  272 \t loss : tensor(1.4321, device='cuda:0')\n",
      "Epoch :  273 \t loss : tensor(1.4352, device='cuda:0')\n",
      "Epoch :  274 \t loss : tensor(1.4396, device='cuda:0')\n",
      "Epoch :  275 \t loss : tensor(1.4471, device='cuda:0')\n",
      "Epoch :  276 \t loss : tensor(1.4481, device='cuda:0')\n",
      "Epoch :  277 \t loss : tensor(1.4268, device='cuda:0')\n",
      "Epoch :  278 \t loss : tensor(1.4221, device='cuda:0')\n",
      "Epoch :  279 \t loss : tensor(1.4330, device='cuda:0')\n",
      "Epoch :  280 \t loss : tensor(1.4342, device='cuda:0')\n",
      "Epoch :  281 \t loss : tensor(1.4298, device='cuda:0')\n",
      "Epoch :  282 \t loss : tensor(1.4380, device='cuda:0')\n",
      "Epoch :  283 \t loss : tensor(1.4342, device='cuda:0')\n",
      "Epoch :  284 \t loss : tensor(1.4414, device='cuda:0')\n",
      "Epoch :  285 \t loss : tensor(1.4369, device='cuda:0')\n",
      "Epoch :  286 \t loss : tensor(1.4277, device='cuda:0')\n",
      "Epoch :  287 \t loss : tensor(1.4432, device='cuda:0')\n",
      "Epoch :  288 \t loss : tensor(1.4269, device='cuda:0')\n",
      "Epoch :  289 \t loss : tensor(1.4497, device='cuda:0')\n",
      "Epoch :  290 \t loss : tensor(1.4548, device='cuda:0')\n",
      "Epoch :  291 \t loss : tensor(1.4406, device='cuda:0')\n",
      "Epoch :  292 \t loss : tensor(1.4446, device='cuda:0')\n",
      "Epoch :  293 \t loss : tensor(1.4430, device='cuda:0')\n",
      "Epoch :  294 \t loss : tensor(1.4313, device='cuda:0')\n",
      "Epoch :  295 \t loss : tensor(1.4174, device='cuda:0')\n",
      "Epoch :  296 \t loss : tensor(1.4375, device='cuda:0')\n",
      "Epoch :  297 \t loss : tensor(1.4321, device='cuda:0')\n",
      "Epoch :  298 \t loss : tensor(1.4143, device='cuda:0')\n",
      "Epoch :  299 \t loss : tensor(1.4059, device='cuda:0')\n",
      "Epoch :  300 \t loss : tensor(1.4287, device='cuda:0')\n",
      "Epoch :  301 \t loss : tensor(1.4299, device='cuda:0')\n",
      "Epoch :  302 \t loss : tensor(1.4259, device='cuda:0')\n",
      "Epoch :  303 \t loss : tensor(1.4230, device='cuda:0')\n",
      "Epoch :  304 \t loss : tensor(1.4351, device='cuda:0')\n",
      "Epoch :  305 \t loss : tensor(1.4234, device='cuda:0')\n",
      "Epoch :  306 \t loss : tensor(1.4310, device='cuda:0')\n",
      "Epoch :  307 \t loss : tensor(1.4291, device='cuda:0')\n",
      "Epoch :  308 \t loss : tensor(1.4180, device='cuda:0')\n",
      "Epoch :  309 \t loss : tensor(1.4358, device='cuda:0')\n",
      "Epoch :  310 \t loss : tensor(1.4480, device='cuda:0')\n",
      "Epoch :  311 \t loss : tensor(1.4418, device='cuda:0')\n",
      "Epoch :  312 \t loss : tensor(1.4180, device='cuda:0')\n",
      "Epoch :  313 \t loss : tensor(1.4660, device='cuda:0')\n",
      "Epoch :  314 \t loss : tensor(1.4228, device='cuda:0')\n",
      "Epoch :  315 \t loss : tensor(1.4266, device='cuda:0')\n",
      "Epoch :  316 \t loss : tensor(1.4311, device='cuda:0')\n",
      "Epoch :  317 \t loss : tensor(1.4154, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  318 \t loss : tensor(1.4200, device='cuda:0')\n",
      "Epoch :  319 \t loss : tensor(1.4207, device='cuda:0')\n",
      "Epoch :  320 \t loss : tensor(1.4131, device='cuda:0')\n",
      "Epoch :  321 \t loss : tensor(1.4278, device='cuda:0')\n",
      "Epoch :  322 \t loss : tensor(1.4503, device='cuda:0')\n",
      "Epoch :  323 \t loss : tensor(1.4337, device='cuda:0')\n",
      "Epoch :  324 \t loss : tensor(1.4436, device='cuda:0')\n",
      "Epoch :  325 \t loss : tensor(1.4216, device='cuda:0')\n",
      "Epoch :  326 \t loss : tensor(1.4246, device='cuda:0')\n",
      "Epoch :  327 \t loss : tensor(1.4052, device='cuda:0')\n",
      "Epoch :  328 \t loss : tensor(1.4061, device='cuda:0')\n",
      "Epoch :  329 \t loss : tensor(1.4204, device='cuda:0')\n",
      "Epoch :  330 \t loss : tensor(1.4127, device='cuda:0')\n",
      "Epoch :  331 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  332 \t loss : tensor(1.4336, device='cuda:0')\n",
      "Epoch :  333 \t loss : tensor(1.4271, device='cuda:0')\n",
      "Epoch :  334 \t loss : tensor(1.4275, device='cuda:0')\n",
      "Epoch :  335 \t loss : tensor(1.4187, device='cuda:0')\n",
      "Epoch :  336 \t loss : tensor(1.4341, device='cuda:0')\n",
      "Epoch :  337 \t loss : tensor(1.4228, device='cuda:0')\n",
      "Epoch :  338 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  339 \t loss : tensor(1.4236, device='cuda:0')\n",
      "Epoch :  340 \t loss : tensor(1.4417, device='cuda:0')\n",
      "Epoch :  341 \t loss : tensor(1.4509, device='cuda:0')\n",
      "Epoch :  342 \t loss : tensor(1.4391, device='cuda:0')\n",
      "Epoch :  343 \t loss : tensor(1.4361, device='cuda:0')\n",
      "Epoch :  344 \t loss : tensor(1.4267, device='cuda:0')\n",
      "Epoch :  345 \t loss : tensor(1.4298, device='cuda:0')\n",
      "Epoch :  346 \t loss : tensor(1.4320, device='cuda:0')\n",
      "Epoch :  347 \t loss : tensor(1.4026, device='cuda:0')\n",
      "Epoch :  348 \t loss : tensor(1.4170, device='cuda:0')\n",
      "Epoch :  349 \t loss : tensor(1.4113, device='cuda:0')\n",
      "Epoch :  350 \t loss : tensor(1.4034, device='cuda:0')\n",
      "Epoch :  351 \t loss : tensor(1.4190, device='cuda:0')\n",
      "Epoch :  352 \t loss : tensor(1.4365, device='cuda:0')\n",
      "Epoch :  353 \t loss : tensor(1.4511, device='cuda:0')\n",
      "Epoch :  354 \t loss : tensor(1.4499, device='cuda:0')\n",
      "Epoch :  355 \t loss : tensor(1.4203, device='cuda:0')\n",
      "Epoch :  356 \t loss : tensor(1.4310, device='cuda:0')\n",
      "Epoch :  357 \t loss : tensor(1.4358, device='cuda:0')\n",
      "Epoch :  358 \t loss : tensor(1.3847, device='cuda:0')\n",
      "Epoch :  359 \t loss : tensor(1.4039, device='cuda:0')\n",
      "Epoch :  360 \t loss : tensor(1.4192, device='cuda:0')\n",
      "Epoch :  361 \t loss : tensor(1.4389, device='cuda:0')\n",
      "Epoch :  362 \t loss : tensor(1.4364, device='cuda:0')\n",
      "Epoch :  363 \t loss : tensor(1.4366, device='cuda:0')\n",
      "Epoch :  364 \t loss : tensor(1.4670, device='cuda:0')\n",
      "Epoch :  365 \t loss : tensor(1.4461, device='cuda:0')\n",
      "Epoch :  366 \t loss : tensor(1.4384, device='cuda:0')\n",
      "Epoch :  367 \t loss : tensor(1.4270, device='cuda:0')\n",
      "Epoch :  368 \t loss : tensor(1.4262, device='cuda:0')\n",
      "Epoch :  369 \t loss : tensor(1.4114, device='cuda:0')\n",
      "Epoch :  370 \t loss : tensor(1.3943, device='cuda:0')\n",
      "Epoch :  371 \t loss : tensor(1.4073, device='cuda:0')\n",
      "Epoch :  372 \t loss : tensor(1.4097, device='cuda:0')\n",
      "Epoch :  373 \t loss : tensor(1.4106, device='cuda:0')\n",
      "Epoch :  374 \t loss : tensor(1.4366, device='cuda:0')\n",
      "Epoch :  375 \t loss : tensor(1.4268, device='cuda:0')\n",
      "Epoch :  376 \t loss : tensor(1.4404, device='cuda:0')\n",
      "Epoch :  377 \t loss : tensor(1.4513, device='cuda:0')\n",
      "Epoch :  378 \t loss : tensor(1.4546, device='cuda:0')\n",
      "Epoch :  379 \t loss : tensor(1.4224, device='cuda:0')\n",
      "Epoch :  380 \t loss : tensor(1.4241, device='cuda:0')\n",
      "Epoch :  381 \t loss : tensor(1.4148, device='cuda:0')\n",
      "Epoch :  382 \t loss : tensor(1.4140, device='cuda:0')\n",
      "Epoch :  383 \t loss : tensor(1.4116, device='cuda:0')\n",
      "Epoch :  384 \t loss : tensor(1.4161, device='cuda:0')\n",
      "Epoch :  385 \t loss : tensor(1.4022, device='cuda:0')\n",
      "Epoch :  386 \t loss : tensor(1.4241, device='cuda:0')\n",
      "Epoch :  387 \t loss : tensor(1.4288, device='cuda:0')\n",
      "Epoch :  388 \t loss : tensor(1.4311, device='cuda:0')\n",
      "Epoch :  389 \t loss : tensor(1.4406, device='cuda:0')\n",
      "Epoch :  390 \t loss : tensor(1.4660, device='cuda:0')\n",
      "Epoch :  391 \t loss : tensor(1.4435, device='cuda:0')\n",
      "Epoch :  392 \t loss : tensor(1.4553, device='cuda:0')\n",
      "Epoch :  393 \t loss : tensor(1.4246, device='cuda:0')\n",
      "Epoch :  394 \t loss : tensor(1.4360, device='cuda:0')\n",
      "Epoch :  395 \t loss : tensor(1.4240, device='cuda:0')\n",
      "Epoch :  396 \t loss : tensor(1.4147, device='cuda:0')\n",
      "Epoch :  397 \t loss : tensor(1.4106, device='cuda:0')\n",
      "Epoch :  398 \t loss : tensor(1.3963, device='cuda:0')\n",
      "Epoch :  399 \t loss : tensor(1.4223, device='cuda:0')\n",
      "Epoch :  400 \t loss : tensor(1.4236, device='cuda:0')\n",
      "Epoch :  401 \t loss : tensor(1.4357, device='cuda:0')\n",
      "Epoch :  402 \t loss : tensor(1.4293, device='cuda:0')\n",
      "Epoch :  403 \t loss : tensor(1.4397, device='cuda:0')\n",
      "Epoch :  404 \t loss : tensor(1.4334, device='cuda:0')\n",
      "Epoch :  405 \t loss : tensor(1.4328, device='cuda:0')\n",
      "Epoch :  406 \t loss : tensor(1.4327, device='cuda:0')\n",
      "Epoch :  407 \t loss : tensor(1.4296, device='cuda:0')\n",
      "Epoch :  408 \t loss : tensor(1.4229, device='cuda:0')\n",
      "Epoch :  409 \t loss : tensor(1.4095, device='cuda:0')\n",
      "Epoch :  410 \t loss : tensor(1.4292, device='cuda:0')\n",
      "Epoch :  411 \t loss : tensor(1.4297, device='cuda:0')\n",
      "Epoch :  412 \t loss : tensor(1.4336, device='cuda:0')\n",
      "Epoch :  413 \t loss : tensor(1.4255, device='cuda:0')\n",
      "Epoch :  414 \t loss : tensor(1.4389, device='cuda:0')\n",
      "Epoch :  415 \t loss : tensor(1.4235, device='cuda:0')\n",
      "Epoch :  416 \t loss : tensor(1.4366, device='cuda:0')\n",
      "Epoch :  417 \t loss : tensor(1.4294, device='cuda:0')\n",
      "Epoch :  418 \t loss : tensor(1.4336, device='cuda:0')\n",
      "Epoch :  419 \t loss : tensor(1.4391, device='cuda:0')\n",
      "Epoch :  420 \t loss : tensor(1.4290, device='cuda:0')\n",
      "Epoch :  421 \t loss : tensor(1.4230, device='cuda:0')\n",
      "Epoch :  422 \t loss : tensor(1.4194, device='cuda:0')\n",
      "Epoch :  423 \t loss : tensor(1.4149, device='cuda:0')\n",
      "Epoch :  424 \t loss : tensor(1.4097, device='cuda:0')\n",
      "Epoch :  425 \t loss : tensor(1.4106, device='cuda:0')\n",
      "Epoch :  426 \t loss : tensor(1.4086, device='cuda:0')\n",
      "Epoch :  427 \t loss : tensor(1.4099, device='cuda:0')\n",
      "Epoch :  428 \t loss : tensor(1.4500, device='cuda:0')\n",
      "Epoch :  429 \t loss : tensor(1.4283, device='cuda:0')\n",
      "Epoch :  430 \t loss : tensor(1.4648, device='cuda:0')\n",
      "Epoch :  431 \t loss : tensor(1.4403, device='cuda:0')\n",
      "Epoch :  432 \t loss : tensor(1.4327, device='cuda:0')\n",
      "Epoch :  433 \t loss : tensor(1.4378, device='cuda:0')\n",
      "Epoch :  434 \t loss : tensor(1.4284, device='cuda:0')\n",
      "Epoch :  435 \t loss : tensor(1.4038, device='cuda:0')\n",
      "Epoch :  436 \t loss : tensor(1.4286, device='cuda:0')\n",
      "Epoch :  437 \t loss : tensor(1.4171, device='cuda:0')\n",
      "Epoch :  438 \t loss : tensor(1.4224, device='cuda:0')\n",
      "Epoch :  439 \t loss : tensor(1.4309, device='cuda:0')\n",
      "Epoch :  440 \t loss : tensor(1.4513, device='cuda:0')\n",
      "Epoch :  441 \t loss : tensor(1.4402, device='cuda:0')\n",
      "Epoch :  442 \t loss : tensor(1.4386, device='cuda:0')\n",
      "Epoch :  443 \t loss : tensor(1.4221, device='cuda:0')\n",
      "Epoch :  444 \t loss : tensor(1.4233, device='cuda:0')\n",
      "Epoch :  445 \t loss : tensor(1.4223, device='cuda:0')\n",
      "Epoch :  446 \t loss : tensor(1.4001, device='cuda:0')\n",
      "Epoch :  447 \t loss : tensor(1.4173, device='cuda:0')\n",
      "Epoch :  448 \t loss : tensor(1.4449, device='cuda:0')\n",
      "Epoch :  449 \t loss : tensor(1.4062, device='cuda:0')\n",
      "Epoch :  450 \t loss : tensor(1.4327, device='cuda:0')\n",
      "Epoch :  451 \t loss : tensor(1.4276, device='cuda:0')\n",
      "Epoch :  452 \t loss : tensor(1.4195, device='cuda:0')\n",
      "Epoch :  453 \t loss : tensor(1.4010, device='cuda:0')\n",
      "Epoch :  454 \t loss : tensor(1.4425, device='cuda:0')\n",
      "Epoch :  455 \t loss : tensor(1.4580, device='cuda:0')\n",
      "Epoch :  456 \t loss : tensor(1.4589, device='cuda:0')\n",
      "Epoch :  457 \t loss : tensor(1.4511, device='cuda:0')\n",
      "Epoch :  458 \t loss : tensor(1.4395, device='cuda:0')\n",
      "Epoch :  459 \t loss : tensor(1.4620, device='cuda:0')\n",
      "Epoch :  460 \t loss : tensor(1.4252, device='cuda:0')\n",
      "Epoch :  461 \t loss : tensor(1.4129, device='cuda:0')\n",
      "Epoch :  462 \t loss : tensor(1.4377, device='cuda:0')\n",
      "Epoch :  463 \t loss : tensor(1.4218, device='cuda:0')\n",
      "Epoch :  464 \t loss : tensor(1.3936, device='cuda:0')\n",
      "Epoch :  465 \t loss : tensor(1.4171, device='cuda:0')\n",
      "Epoch :  466 \t loss : tensor(1.4178, device='cuda:0')\n",
      "Epoch :  467 \t loss : tensor(1.4238, device='cuda:0')\n",
      "Epoch :  468 \t loss : tensor(1.4271, device='cuda:0')\n",
      "Epoch :  469 \t loss : tensor(1.4298, device='cuda:0')\n",
      "Epoch :  470 \t loss : tensor(1.4319, device='cuda:0')\n",
      "Epoch :  471 \t loss : tensor(1.4418, device='cuda:0')\n",
      "Epoch :  472 \t loss : tensor(1.4664, device='cuda:0')\n",
      "Epoch :  473 \t loss : tensor(1.4595, device='cuda:0')\n",
      "Epoch :  474 \t loss : tensor(1.4175, device='cuda:0')\n",
      "Epoch :  475 \t loss : tensor(1.4368, device='cuda:0')\n",
      "Epoch :  476 \t loss : tensor(1.4288, device='cuda:0')\n",
      "Epoch :  477 \t loss : tensor(1.4192, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  478 \t loss : tensor(1.4337, device='cuda:0')\n",
      "Epoch :  479 \t loss : tensor(1.4256, device='cuda:0')\n",
      "Epoch :  480 \t loss : tensor(1.4111, device='cuda:0')\n",
      "Epoch :  481 \t loss : tensor(1.4089, device='cuda:0')\n",
      "Epoch :  482 \t loss : tensor(1.4093, device='cuda:0')\n",
      "Epoch :  483 \t loss : tensor(1.4129, device='cuda:0')\n",
      "Epoch :  484 \t loss : tensor(1.4055, device='cuda:0')\n",
      "Epoch :  485 \t loss : tensor(1.4351, device='cuda:0')\n",
      "Epoch :  486 \t loss : tensor(1.4548, device='cuda:0')\n",
      "Epoch :  487 \t loss : tensor(1.4559, device='cuda:0')\n",
      "Epoch :  488 \t loss : tensor(1.4434, device='cuda:0')\n",
      "Epoch :  489 \t loss : tensor(1.4476, device='cuda:0')\n",
      "Epoch :  490 \t loss : tensor(1.4456, device='cuda:0')\n",
      "Epoch :  491 \t loss : tensor(1.4338, device='cuda:0')\n",
      "Epoch :  492 \t loss : tensor(1.4323, device='cuda:0')\n",
      "Epoch :  493 \t loss : tensor(1.4322, device='cuda:0')\n",
      "Epoch :  494 \t loss : tensor(1.4397, device='cuda:0')\n",
      "Epoch :  495 \t loss : tensor(1.4306, device='cuda:0')\n",
      "Epoch :  496 \t loss : tensor(1.4424, device='cuda:0')\n",
      "Epoch :  497 \t loss : tensor(1.4124, device='cuda:0')\n",
      "Epoch :  498 \t loss : tensor(1.4226, device='cuda:0')\n",
      "Epoch :  499 \t loss : tensor(1.4132, device='cuda:0')\n",
      "Epoch :  500 \t loss : tensor(1.4268, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XuYXXV97/H3d+3L7LllMkkmFxIw3CyGS0IYMAiC4AHxhlq1SKngrbGnaqFUe6L21Kj4QK1KtQf1RIjiU+VS1IMFW0oRjJxjgwmEi0QaSOAhQ5KZhEzmPvuyvuePvWZnMrMnM5n7mnxezzPP7L322nt91zB88pvf+v1+y9wdERGJv2CqCxARkfGhQBcRmSEU6CIiM4QCXURkhlCgi4jMEAp0EZEZQoEuIjJDKNBFRGYIBbqIyAyRnMyDzZs3z5cuXTqZhxQRib3NmzfvdfeG4fab1EBfunQpmzZtmsxDiojEnpm9NJL91OUiIjJDjDjQzSxhZk+Y2X3R8+PNbKOZPW9md5lZeuLKFBGR4RxJC/1aYGu/538H3OzuJwH7gY+OZ2EiInJkRtSHbmZLgLcDXwGuNzMDLgb+ONrldmAt8J0JqFFEprFcLsfOnTvp6emZ6lJiL5PJsGTJElKp1KjeP9KLov8A/DVQGz2fC7S6ez56vhNYPKoKRCTWdu7cSW1tLUuXLqXY1pPRcHf27dvHzp07Of7440f1GcN2uZjZO4Bmd988mgOY2Woz22Rmm1paWkbzESIyjfX09DB37lyF+RiZGXPnzh3TXzoj6UM/D7jczF4E7qTY1fJNYLaZ9bXwlwBN5d7s7uvcvdHdGxsahh1GKSIxpDAfH2P9OQ4b6O7+WXdf4u5LgQ8Av3T3q4CHgfdFu10D3DumSobzXw/AgbL/ZoiICGMbh/4/KF4gfZ5in/pt41PSEH78R7Duwgk9hIjEz759+1ixYgUrVqxg4cKFLF68uPQ8m82O6DM+/OEP89xzz434mLfeeivXXXfdaEueMEc0U9TdHwEeiR5vB84Z/5IOo1N98CJyqLlz57JlyxYA1q5dS01NDZ/+9KcP2cfdcXeCoHwb9vvf//6E1zkZNFNURGak559/nmXLlnHVVVdx6qmnsmvXLlavXk1jYyOnnnoqX/rSl0r7nn/++WzZsoV8Ps/s2bNZs2YNy5cv59xzz6W5ufmwx9mxYwcXXXQRZ5xxBpdccgk7d+4E4M477+S0005j+fLlXHTRRQA8/fTTnH322axYsYIzzjiD7du3j+s5T+paLiIys33xX37Hs6+0jetnLjtmFl9456mjeu/vf/97fvjDH9LY2AjATTfdxJw5c8jn81x00UW8733vY9myZYe858CBA1x44YXcdNNNXH/99axfv541a9YMeYw///M/52Mf+xhXXXUV69at47rrruOee+7hi1/8Io888ggLFiygtbUVgG9/+9t8+tOf5oorrqC3txd3H9V5DUUtdBGZsU488cRSmAPccccdrFy5kpUrV7J161aeffbZQe+prKzkrW99KwBnnXUWL7744mGPsXHjRj7wgQ8AcPXVV/PrX/8agPPOO4+rr76aW2+9lTAMAXjDG97ADTfcwFe/+lVefvllMpnMeJxmiVroIjJuRtuSnijV1dWlx9u2beOb3/wmjz32GLNnz+ZP/uRPyo75TqcPLkuVSCTI5/OD9hmJ733ve2zcuJH77ruPlStX8sQTT/DBD36Qc889l/vvv5/LLruM9evXc8EFF4zq88tRC11EjgptbW3U1tYya9Ysdu3axQMPPDAun7tq1SruvvtuAP7pn/6pFNDbt29n1apVfPnLX6a+vp6mpia2b9/OSSedxLXXXss73vEOnnrqqXGpoY9a6CJyVFi5ciXLli3jlFNO4TWveQ3nnXfeuHzuLbfcwkc+8hFuvPFGFixYUBox85d/+Zfs2LEDd+fSSy/ltNNO44YbbuCOO+4glUpxzDHHsHbt2nGpoY+Nd6f84TQ2Nvqob3Cxti76fmD8ChKRMdu6dSuve93rprqMGaPcz9PMNrt74xBvKYlHl0u/f3TW/GR8/0QREZkpYhfod/725SksRERk+opHoDN53UIiInEVj0CfxH5+EZG4ikegi4jIsGIS6Ie20CdzZI6ISFzEI9AHBHhvPpyiQkRkJqipqTmi7XERj0Af0ELv7B3dVFwRkZksHoHuAwO9MEWFiMh0s2bNGm655ZbS87Vr1/K1r32Njo4O3vzmN7Ny5UpOP/107r135DdVc3c+85nPcNppp3H66adz1113AbBr1y4uuOACVqxYwWmnncavf/1rCoUCH/rQh0r73nzzzeN+jiMVy6n/HWqhi0xP/7oGdj89vp+58HR4601DvnzFFVdw3XXX8YlPfAKAu+++mwceeIBMJsPPfvYzZs2axd69e1m1ahWXX375iO7b+dOf/pQtW7bw5JNPsnfvXs4++2wuuOACfvzjH/OWt7yFz3/+8xQKBbq6utiyZQtNTU0888wzAKWlcqfCsIFuZhlgA1AR7X+Pu3/BzH4AXAj0zcX/kLtvmZgyB7TQswp0ESk688wzaW5u5pVXXqGlpYX6+nqOPfZYcrkcn/vc59iwYQNBENDU1MSePXtYuHDhsJ/56KOPcuWVV5JIJFiwYAEXXnghv/3tbzn77LP5yEc+Qi6X493vfjcrVqzghBNOYPv27XzqU5/i7W9/O5deeukknHV5I2mh9wIXu3uHmaWAR83sX6PXPuPu90xceZEBXS5qoYtMU4dpSU+k97///dxzzz3s3r2bK664AoAf/ehHtLS0sHnzZlKpFEuXLi27XO6RuOCCC9iwYQP3338/H/rQh7j++uu5+uqrefLJJ3nggQf47ne/y91338369evH47SO2LB96F7UET1NRV+TPG5QF0VFZGhXXHEFd955J/fccw/vf//7geKdh+bPn08qleLhhx/mpZdeGvHnvfGNb+Suu+6iUCjQ0tLChg0bOOecc3jppZdYsGABf/qnf8rHPvYxHn/8cfbu3UsYhrz3ve/lhhtu4PHHH5+o0xzWiPrQzSwBbAZOAm5x941m9t+Br5jZ3wIPAWvcvXdCqhzQQs9q2KKI9HPqqafS3t7O4sWLWbRoEQBXXXUV73znOzn99NNpbGzklFNOGfHnvec97+E3v/kNy5cvx8z46le/ysKFC7n99tv5+7//e1KpFDU1Nfzwhz+kqamJD3/4w6W7Et14440Tco4jcUTL55rZbOBnwKeAfcBuIA2sA15w9y+Vec9qYDXAcccdd9aR/CtZ0tsBNy4GYGnPj/n6+5fz3rOWHPnniMi40/K542vSls9191bgYeAyd98Vdcf0At8HzhniPevcvdHdGxsaGo7kcP0/5TDPREQERhDoZtYQtcwxs0rgEuD3ZrYo2mbAu4FnJqzKAX9FhJr6LyIyyEj60BcBt0f96AFwt7vfZ2a/NLMGwIAtwJ9NXJl+2KciMrXcfUTju+XwxrpO1bCB7u5PAWeW2X7xmI48Bq5EF5k2MpkM+/btY+7cuQr1MXB39u3bRyaTGfVnxGOm6KAulymqQ0QGWbJkCTt37qSlpWWqS4m9TCbDkiWjH/ARj0AftHzuFJUhIoOkUimOP/74qS5DiOniXOpyEREZLB6BPoC6XEREBotloKvPRURksHgE+qAuFxERGSgegT4gwkP1uYiIDBKPQFcLXURkWPEIdA1bFBEZVkwC/VBay0VEZLB4BLoCXERkWPEIdHW5iIgMKx6BruVzRUSGFY9A1w0uRESGFZNAP+hbqX+kpmvnVJchIjLtxCPQ+3WxXJ74DWfv+O4UFiMiMj3FI9AHdLJ0VMyfojpERKavkdxTNGNmj5nZk2b2OzP7YrT9eDPbaGbPm9ldZpaesCoHXARtq1g4YYcSEYmrkbTQe4GL3X05sAK4zMxWAX8H3OzuJwH7gY9OXJmHBnrBUhN3KBGRmBo20L2oI3qair4cuBi4J9p+O/DuCamwfFGTdigRkbgYUR+6mSXMbAvQDDwIvAC0uns+2mUnsHhiSqRMgBcm7FAiInE1okB394K7rwCWAOcAp4z0AGa22sw2mdmm0d5E1j08dIOWzxURGeSIRrm4eyvwMHAuMNvM+m4yvQRoGuI969y90d0bGxoaRlXkwAa6DQx4EREZ0SiXBjObHT2uBC4BtlIM9vdFu10D3DtRRQ5ujyvQRUQGSg6/C4uA280sQfEfgLvd/T4zexa408xuAJ4AbpuoIj0MB26YqEOJiMTWsIHu7k8BZ5bZvp1if/qE84FtdAW6iMggsZgp6gM60U3Lc4mIDBKLQB/YIh806kVEROIR6BrlIiIyvFgE+qBxLgp0EZFBYhHoPmAikVroIiKDxSPQB44711ouIiKDxCPQBwa4WugiIoPEI9Cj7/mgYsAWERHpE4tA71uM61ev+xIApi4XEZFBYhHopZmiZhQwcC2fKyIyUDwCPWqROxASaKaoiEgZsQj0vi4XswDHdFFURKSMWAR6/y6XkECBLiJSRiwCvW/cuQGO6aKoiEgZsQj00jh0M0IM0w0uREQGiV2gu7pcRETKikeg03dRVC10EZGhjOSeosea2cNm9qyZ/c7Mro22rzWzJjPbEn29bcKqLHWZWzTKRX3oIiIDjeSeonngr9z9cTOrBTab2YPRaze7+9cmrryi0uJcFo1DV5eLiMggI7mn6C5gV/S43cy2AosnurBDlJbPjVro6nIRERnkiPrQzWwpxRtGb4w2fdLMnjKz9WZWP861lfTvQ3cCAnW5iIgMMuJAN7Ma4CfAde7eBnwHOBFYQbEF//Uh3rfazDaZ2aaWlpZRFXkwvwNC00xREZFyRhToZpaiGOY/cvefArj7HncvePGOzd8Dzin3Xndf5+6N7t7Y0NAwyjLDqI5oYpHWchERGWQko1wMuA3Y6u7f6Ld9Ub/d3gM8M/7lFfVvkGstFxGR8kYyyuU84IPA02a2Jdr2OeBKM1tBcVDhi8DHJ6RCDl3LxQnQDS5ERAYbySiXRykuozLQL8a/nKGKiLpcCIoTi9RCFxEZJB4zRaMGuZupD11EZAixCPS+LhYD3DSxSESknFgEuof9x6EXF9EVEZFDxSLQSzNDoxtcqIUuIjJYLAK9NLGo1IeuQBcRGSgegR59N7OoD11dLiIiA8Ui0PtPJFILXUSkvFgEet8di6x0k2i10EVEBopFoPfrRFcLXURkCPEI9NIol0Dj0EVEhhCLQO93j2jNFBURGUKsAh3ANQ5dRKSsWAQ6pYuiARhqoYuIlBGLQPeBM0V1UVREZJBYBHqphd53k2gNWxQRGSQWgX7I1H8L1OUiIlJGPAK9X4DroqiISHkjuafosWb2sJk9a2a/M7Nro+1zzOxBM9sWfa+fsCoHLJ+rFrqIyGAjaaHngb9y92XAKuATZrYMWAM85O4nAw9FzydIv3uKWkCgi6IiIoMMG+juvsvdH48etwNbgcXAu4Dbo91uB949UUUenFgUFFvouigqIjLIEfWhm9lS4ExgI7DA3XdFL+0GFoxrZYfo1yI3DVsUESlnxIFuZjXAT4Dr3L2t/2teXA6xbLPZzFab2SYz29TS0jKqIvuvtqg+dBGR8kYU6GaWohjmP3L3n0ab95jZouj1RUBzufe6+zp3b3T3xoaGhtFVWepzQROLRESGMJJRLgbcBmx192/0e+nnwDXR42uAe8e/vKJSC52g2OWiPnQRkUGSI9jnPOCDwNNmtiXa9jngJuBuM/so8BLwRxNTYr++HDPctB66iEg5wwa6uz8K2BAvv3l8yxmyCIiKCDEC9aGLiAwSi5mipVEuQVCcKaoWuojIIPEI9H4tdFcfuohIWbEI9P6Lc6F7ioqIlBWPQI++G0F0UVQtdBGRgWIR6ESrKxbvKaouFxGRcmIR6N7/LtFaD11EpKxYBHq/1blwM622KCJSRjwCnf63oFMLXUSknHgE+iG3oNMoFxGRcmIR6M7BcegQaKaoiEgZ8Qj0vlEuQaCJRSIiQ4hFoB+8A13feujqchERGSgWgd7/BheYulxERMqJRaD3NdEdAy3OJSJSViwC/WALHULT8rkiIuXEItAZ0OWicegiIoPFI9D7hi1aQHHYorpcREQGGsk9RdebWbOZPdNv21ozazKzLdHX2ya0yoPr5xJaQEKBLiIyyEha6D8ALiuz/WZ3XxF9/WJ8yzpU/+XQ84lKUuQhn53IQ4qIxM6wge7uG4BXJ6GWwxUBFNdDzwaVxW25ziksSERk+hlLH/onzeypqEumftwqKqM0yiWA3qCquDGrQBcR6W+0gf4d4ERgBbAL+PpQO5rZajPbZGabWlpaRnm4g+PQc4moha5AFxE5xKgC3d33uHvBi4usfA845zD7rnP3RndvbGhoGFWR3m/q/8FA7xjVZ4mIzFSjCnQzW9Tv6XuAZ4badzz0zQw1jKy6XEREykoOt4OZ3QG8CZhnZjuBLwBvMrMVFPtCXgQ+PoE19utDN3JJBbqISDnDBrq7X1lm820TUMvwzMglioH+i83buPSkt5BMxGRulIjIBItHGh4ybLEY6G/7r//Jw1uem8qqRESmlVgEeumORYGR7+tyAer3Pz1VJYmITDuxCPSDLXTIJTKlzVY1ocPfRURiJRaB7qVxi2DBwW7/isQUFSQiMg3FItAPruYSFJfQ7VPIT0k1IiLTUTwCvd+wRQM+kP2b4uawMIVFiYhML/EI9IhhVKQSFLxYdljITXFFIiLTRywCvf9Noo+py1CgL9DVQhcR6ROLQD84ysVYNLvyYKCH6kMXEekTj0DvuygaGItnZ8hTHN7iuigqIlISj0DvN1N0UV0lBQW6iMggsQj0/regq65IlrpcXF0uIiIlsQj0gzeJLvrHP24sbtawRRGRklgFugXFSUX1tcWbXKjLRUTkoHgEet/iXFYsN5EoTv9XC11E5KB4BPrBe9ABEJQCXS10EZE+sQj0gxdFi4GeSEaBrolFIiIlwwa6ma03s2Yze6bftjlm9qCZbYu+T+w6tv0mFsHBLhfUQhcRKRlJC/0HwGUDtq0BHnL3k4GHoucT6ODUf4BEMl3c6mqhi4j0GTbQ3X0D8OqAze8Cbo8e3w68e5zrGlgE0C/QE9FC6BrlIiJSMto+9AXuvit6vBtYME71lFUahR4FejKZKj5Xl4uISMmYL4p6cSlEH+p1M1ttZpvMbFNLS8sojxIWPyvqQw+iQNewRRGRg0Yb6HvMbBFA9L15qB3dfZ27N7p7Y0NDw+iO1jdqMZpYhEVdLmqhi4iUjDbQfw5cEz2+Brh3fMoZwoCp/wRRoOuiqIhIyUiGLd4B/Ab4AzPbaWYfBW4CLjGzbcB/i55PoKjLJZopihkFN0xdLiIiJcnhdnD3K4d46c3jXMvQNUTf+98gumAJ9aGLiPQTi5miHDrzH4ACAfs7usjmw6mpSURkmolHoHPwBhd9zJ3LO3/Cbff8y1QVJSIyrcQj0D1qhQcHm+gZywFw2bYvTEVFIiLTTjwCPdK/D71PgLpcREQgLoFe6kMfHOgJBbqICBCXQC8NWxwc6GZDTlIVETmqxCLQS/e3oFyXiwJdRARiEuilUS6B+tBFRIYSj0D3wcMW+6iFLiJSFI9AVwtdRGRY8Qj0wzTCA1egi4hAXAJ9wC3oDqVAFxGBuAR66RZ0g8u1gUvriogcpWIW6INfSnhukosREZmeYhHoDoRebhQ6ZLxnsssREZmWYhHoh+tDT5GHXPdkFyQiMu3EJtAdyrbQAdj/0iTWIiIyPQ17x6LDMbMXgXagAOTdvXE8ihrEHccoMwy9aP8OmH/KhBxaRCQuxqOFfpG7r5iwMI84NsSwRdj23NO4RruIyFEuHl0u5cL64xu4/Q++S4dnWLD5G9zxyOOTX5eIyDQy1kB34N/NbLOZrR6PgoY6zKBIX7Sc5jln8r3825ll3Sze+JWJO7yISAyMqQ8dON/dm8xsPvCgmf3e3Tf03yEK+tUAxx133OiOEvWhD5RJJvh64b3MsTY+0PNIcbRLqnJ0xxARibkxtdDdvSn63gz8DDinzD7r3L3R3RsbGhpGeyTKjXFZfuxsAB4JV1BBjp7t/2+Uny8iEn+jDnQzqzaz2r7HwKXAM+NV2CG8/Ppcq06YC8BjYXGES/vz/zkhhxcRiYOxdLksAH4WjTxJAj92938bl6oGKT+CJZ0MuP8vzuflV7vY88+zybe8MDGHFxGJgVEHurtvB5aPYy2HO1rZPnSAU4+pY1FdJS/4fJa0vjg55YiITEOxGbY4VKADzKlOsyexkEzny5NYlIjI9BKPQC83bHGAnprXUJdt4Vv/9lT0Fk00EpGjS0wCHQ6zkgsA2zOnEpjzF//5Rnp+dTPcsABa1WIXkaNHPAJ9BK3t8y/9w9LjzMNrodALj62bwKJERKaX2AT64frQAd5w8gLCTx46/X/3ln+dyKpERKaVeAT6CPrQAYJ5J/J8ZXHgzaOFU6nv3EFza/vEliYiMk3EJNAZtoXeJ3jtJWwKX8s9hQupsDwPPfp/J7gyEZHpISaBftjbWxxi6bv+hp+suI0P/uHlADzznw9y66+305MrTGB9IiJTb6yLc00O95HmOUFg3PiHZ4A73RuO5/LWR9n0QDO//I1R+56v88YT6iERj9MWETkSMWmhDzX5/zDMqHz9R3h98Hs+kfw5b+u6lzu+/y348lxo2jwRJYqITKl4BLqHI+5DP8Tr/wyOv6D09NvpbwFw4D++Rhhq4pGIzCzxCHRGflH0EMk0XPMvbPv4S/xF9pPkPAFA3Y5fsO2mN7Dr377OQ8/uZvWtv2Jny6sQhnCgCTath+7W6MAKfhGJB5vMe3E2Njb6pk2bjvh9G//Xh3nt3gepX7tz1Mf+zQv7WFm7n9/tc175P1/gDT2/Yo51HLJPq9cwO9rWZdX0JqqoDdt59Q+uoGPRuVQ0b6G1dT9Vi15HYuHrqO7ZTWb3ZtLHnUVToR6691MXtlJRWQ0Np3AgmM3cRAe55u1kQydRUU0qlSSV7yKZa6c9TBMYVM1ZTH7vDnotTb5yPvlMPbODbuyVzeQtRbhwOXS/iuW6IZEmzNRj3a8SzlpCsH879LZDRS0272RSYQ8Jz0MYUsh209vbTdWSMwi7XiWXy5Pq3kO2ZjHdne14GNLrSdKV1czK7iHZ20pYs5DQkhTyObx2EclEQCqZgv07CLteJZ+qIezthO79BHXH0JGF2mwLGOTSdVC3hB5Pke3tpbpnN149n85syOzKBJkEZHNZLJGmp6uDDD2kLIR0NbmeTgrzTiHf2gSV9XTlnNqwjSCVIdXzKq9mE1TV1lFVWYn1tkFlPd7bXvxHOF1Nd/s+6GmloqIaKmrxZBpyPdDdSpiugUIOuvYSVs/Hq+dD937SqRSJZBo/sBMSafKJClKeh0IWT1WRb1iGte/CO1sIMnUkKEDtImjfBZk6wMjmc2SzBZJBSEUCCoWQwEMCC+nN5TEPwUMShIRhSCqVhkwdYU8boSWKP2tLkEmnsCBJNoTACyQ6dxOmavH2XSTnnQhBErDi9Z+2XRDmizdzydRRSNXg2Q56s1kqgpAETiH6C7Qnm6ciGeAe4u5YkMDrFmOAFbIEHXuwbBtWPQ9LVEDtAnh1O+R6KBzYSSE9i6DuGJKzFkG6BrIdFA68goV5gp79xRqq55PH6M4b1dW1hB17yHXuJ9Gxh2SmmqCmAVJVUD2PgkPQ00oYXRYL+u78HiRwIOw6QBD20llIUl1ZgUX51BsGkMqQTGdIJNOw73nC7lYsSED1fAqpKsxDAgML85DvASCfqsESaQpd+0lXVIIFUDkH9m2Drn2QqiKf7SFXfyLZni4KsxaTyraTCnuoIEtPdwfJ9l2k6hdDqpJCUIGlq8knMqTSFRiQ3fMchY4WCJIEqQwVVXV4kKSjt0BNZYqCG9mCk1h4KhW1c0eVX2a2eST3bY5HoP/jNbx23y+pXzt+U/lf3tdB6ofvYOGBJwDYl5hHbz5knrXxk/AilvECr7E9vODHcFawrfS+Ds9QYz2l51lPkDaNoBGRw3v24vUsu+C9o3rvSAM9FsM9Zp3xdl5sWkr9OH7msXNr4BP3Q08bzFrEXMDDEMt18UepanKFkOd2t5NJGA807WR+1zYOeDXHLlvFk007SO7bRmcOdlSdTtD6IvMSnYQVs2kNZtHb1cHSzqeoTIS0eRU9dSeSSCagt5N8PkcvKfZ3O/NnV5HOd9B9oJm22pOpThao7GmhutBOWyHJSxWvZWG1sfDAk7RnjiGXrCER5qjM7gULSBW66KxYQD5RSVV2L5brpNsz9IRGNjRynqAqyFHTu4cwU08yEbA7W8kxqXasopYgkaQ2maentZmm5BK6g2oa8q8QWgVJK1BR6IAwJJ/roTWzhHxmLvOzL5O3FHtSx1JZaCNtBXqCagqWoqrQRl1+L5lESEXC6MnlyRWgsqqazp5euvNgyQryBaeyuoZOr6C9Owu5bjKVlSzofoF89SJS+XZSiQT7vYZEoZtmr2NxjRH2tNPb1UEuSJMmTy5ZAziJQg+Jqjlkk7Xks90kC12kwl4KQQX5VA0V+TZyySp6U7OZ1bOLinw7venZdPZkSYa9dFcuoqurk7oKoy1nWLKCeYVm6ntf4UBqPl4xCy/kyTpUdLfQ5pUEYY6KdJIgSDKrqoJsATpyTjqZIMTIhQEWBPQWoCKVoisfUpVOk8t2U11oJ1dRR5ICSXMSnqeju5eEhVQmDDejLTGHqrCDMEgX/xKJOh2TnqMrPZccSRL5LjLeTY13k0tWQSJF1o3ePKQSAR29eeoq0zhGkAiKLeIwS3VvMwUShCToTM8jF2RI5dqozO4jGXazt+I1dIRpqJpLXSJHomsP1tlMNd0UUrXkKurJBRV0BrNI5A6QznVQmTQyiZDujjbyVfMJquroSs6m0NtFomc/gWepzu6nIghpS9STSgQ4Tq7ghKGTIk8qcLLp2bTmAualC7R1Z0mnknRn88zJBCQ9B4VerJClIz2XXGo2eUuSybVSU2ijEKQoEJAnSben6M7maEjnyOd6CRIVBIVuwkQldLWwP72I9oqFVIQ9VCScubndVFZWUpfdTWeynm4y7O0NqK6poSMxl3SBlc+OAAAE20lEQVT7DpKJJCkK5Ho6mJXIcaCzi8ALBHNOJF+ziAQ5erq76elsI5MIqUwZuXxIKoB00jjrhNePY4KVF4sWuojI0WykLfTYXBQVEZHDG1Ogm9llZvacmT1vZmvGqygRETlyY7lJdAK4BXgrsAy40syWjVdhIiJyZMbSQj8HeN7dt7t7FrgTeNf4lCUiIkdqLIG+GOg/jnBntE1ERKbAhF8UNbPVZrbJzDa1tLRM9OFERI5aYwn0JuDYfs+XRNsO4e7r3L3R3RsbGhrGcDgRETmcsQT6b4GTzex4M0sDHwB+Pj5liYjIkRrTxCIzexvwD0ACWO/uXxlm/xbgpVEebh6wd5TvjSud89FB53x0GMs5v8bdh+3imNSZomNhZptGMlNqJtE5Hx10zkeHyThnzRQVEZkhFOgiIjNEnAJ93VQXMAV0zkcHnfPRYcLPOTZ96CIicnhxaqGLiMhhxCLQZ+qqjma23syazeyZftvmmNmDZrYt+l4fbTcz+1b0M3jKzFZOXeWjY2bHmtnDZvasmf3OzK6Nts/YcwYws4yZPWZmT0bn/cVo+/FmtjE6v7ui+RyYWUX0/Pno9aVTWf9omVnCzJ4ws/ui5zP6fAHM7EUze9rMtpjZpmjbpP1+T/tAn+GrOv4AuGzAtjXAQ+5+MvBQ9ByK539y9LUa+M4k1Tie8sBfufsyYBXwiei/5Uw+Z4Be4GJ3Xw6sAC4zs1XA3wE3u/tJwH7go9H+HwX2R9tvjvaLo2uBrf2ez/Tz7XORu6/oN0Rx8n6/3X1afwHnAg/0e/5Z4LNTXdc4nt9S4Jl+z58DFkWPFwHPRY//N3Bluf3i+gXcC1xylJ1zFfA48HqKk0yS0fbS7znwAHBu9DgZ7WdTXfsRnueSKLwuBu6jeE/oGXu+/c77RWDegG2T9vs97VvoHH2rOi5w913R493AgujxjPo5RH9Wnwls5Cg456j7YQvQDDwIvAC0uns+2qX/uZXOO3r9ADC628VPnX8A/hoIo+dzmdnn28eBfzezzWa2Oto2ab/fsbhJ9NHK3d3MZtwwJDOrAX4CXOfubWZWem2mnrO7F4AVZjYb+BlwyhSXNGHM7B1As7tvNrM3TXU9k+x8d28ys/nAg2b2+/4vTvTvdxxa6CNa1XEG2WNmiwCi783R9hnxczCzFMUw/5G7/zTaPKPPuT93bwUeptjlMNvM+hpV/c+tdN7R63XAvkkudSzOAy43sxcp3vjmYuCbzNzzLXH3puh7M8V/uM9hEn+/4xDoR9uqjj8HrokeX0Oxn7lv+9XRlfFVwIF+f8bFghWb4rcBW939G/1emrHnDGBmDVHLHDOrpHjdYCvFYH9ftNvA8+77ebwP+KVHnaxx4O6fdfcl7r6U4v+vv3T3q5ih59vHzKrNrLbvMXAp8AyT+fs91RcRRnih4W3Af1Hsd/z8VNczjud1B7ALyFHsP/soxb7Dh4BtwH8Ac6J9jeJonxeAp4HGqa5/FOd7PsU+xqeALdHX22byOUfncQbwRHTezwB/G20/AXgMeB74Z6Ai2p6Jnj8fvX7CVJ/DGM79TcB9R8P5Ruf3ZPT1u76smszfb80UFRGZIeLQ5SIiIiOgQBcRmSEU6CIiM4QCXURkhlCgi4jMEAp0EZEZQoEuIjJDKNBFRGaI/w93Pkvzd4trqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting loss\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
